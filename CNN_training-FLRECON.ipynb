{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2016/12/18/17:00:30'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data')\n",
    "x_size, y_size = 28, 28\n",
    "n_classes = 10\n",
    "\n",
    "n_epochs = 1000\n",
    "original_ckpt_path = './models/MNIST_NLA_vanilla.ckpt'\n",
    "#ckpt_path = './models/MNIST_NLA_vanilla.ckpt'\n",
    "variables_file = './variables/scheme1_fr.npz'\n",
    "activations_file = './variables/scheme1_dr.npz'\n",
    "\n",
    "def timestamp():\n",
    "    d = datetime.datetime.now()\n",
    "    return d.strftime(\"%Y/%m/%d/%X\")\n",
    "\n",
    "timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch_iterator(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "    assert n == y.shape[0]\n",
    "    \n",
    "    while True:\n",
    "        index = np.random.randint(n, size=batch_size)\n",
    "        x_batch, y_batch = x[index], y[index]\n",
    "        yield x_batch.copy(), y_batch.copy()\n",
    "        \n",
    "def batch_iterator(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "    assert n == y.shape[0]\n",
    "    \n",
    "    for i in range(0, n, batch_size):\n",
    "        x_batch, y_batch = x[i:i+batch_size], y[i:i+batch_size]        \n",
    "        yield x_batch.copy(), y_batch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_cnn(inputs, is_training, n_conv, conv_base, conv_mul,\n",
    "              conv_size, pool_size):\n",
    "    l = inputs\n",
    "    for i in range(n_conv):\n",
    "        n_filters = conv_base * conv_mul ** i\n",
    "        l = slim.conv2d(l, n_filters, [conv_size, conv_size],\n",
    "                        scope='conv{}'.format(i+1), is_training=is_training)\n",
    "        l = slim.max_pool2d(l, [pool_size, pool_size], scope='maxpool{}'.format(i+1), is_training=is_training)\n",
    "    l = slim.flatten(l)\n",
    "    \n",
    "    l = slim.dropout(l, 0.5, scope='dropout', is_training=is_training)\n",
    "    l = slim.fully_connected(l, 10, activation_fn=None, scope='logits', is_training=is_training)\n",
    "    return l\n",
    "\n",
    "def build_cnn_method1(inputs, is_training, n_conv, conv_base, conv_mul,\n",
    "              conv_size, pool_size, init_vals):\n",
    "    l = inputs\n",
    "    \n",
    "    for i in range(n_conv):\n",
    "        n_filters = conv_base * conv_mul ** i\n",
    "        M = n_filters // 4\n",
    "        \n",
    "        batch_size, w, h, in_channels = l.get_shape()\n",
    "        \n",
    "        with tf.variable_scope('conv{}'.format(i+1)):\n",
    "            b = init_vals[0][i]\n",
    "            init_val = tf.constant(b, dtype=tf.float32)\n",
    "            #f = tf.get_variable('basis', initializer=init_val,\n",
    "            #                   trainable=False)\n",
    "            l = tf.nn.depthwise_conv2d(l, init_val, [1, 1, 1, 1], padding='SAME', name='dpconv')\n",
    "            a = init_vals[1][i]\n",
    "            init_a = tf.constant(a, dtype=tf.float32)\n",
    "            #f1 = tf.get_variable('a1', initializer=init_a,\n",
    "             #                  trainable=False)\n",
    "            biases = tf.get_variable(shape=[n_filters], name='biases')\n",
    "            l = tf.nn.relu(tf.nn.conv2d(l, init_a, strides=[1, 1, 1, 1], padding='SAME') + biases)\n",
    "            \n",
    "        l = slim.max_pool2d(l, [pool_size, pool_size], scope='maxpool{}'.format(i+1))\n",
    "    l = slim.flatten(l)\n",
    "    \n",
    "    l = slim.dropout(l, 0.5, scope='dropout', is_training=is_training)\n",
    "    l = slim.fully_connected(l, 10, activation_fn=None, scope='logits', trainable=False)\n",
    "    return l\n",
    "\n",
    "def build_loss(logits, y_true):\n",
    "    logloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y_true),\n",
    "                             name='logloss')\n",
    "    return logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "test_list = list(batch_iterator(\n",
    "        mnist.test.images, mnist.test.labels, batch_size=batch_size))\n",
    "\n",
    "n_conv = 2\n",
    "conv_base = 32\n",
    "conv_mul = 2\n",
    "conv_size = 5\n",
    "pool_size = 2\n",
    "\n",
    "def build_model(graph, build_cnn, init_vals):\n",
    "    with graph.as_default():#, graph.device('/cpu:0'):\n",
    "        with tf.variable_scope('model') as vs:\n",
    "            is_training = tf.placeholder(tf.bool)\n",
    "            x_ph = tf.placeholder(tf.float32, shape=[batch_size, x_size * y_size])\n",
    "            x_image = tf.reshape(x_ph, [-1, x_size, y_size, 1])\n",
    "            y_ph = tf.placeholder(tf.int64, shape=[batch_size])\n",
    "            \n",
    "            logits = build_cnn(x_image, is_training=is_training, n_conv=n_conv,\n",
    "                               conv_base=conv_base, conv_mul=conv_mul,\n",
    "                               conv_size=conv_size, pool_size=pool_size, init_vals=init_vals)\n",
    "            \n",
    "            prediction = tf.nn.softmax(logits, name='predictions')\n",
    "\n",
    "            loss = build_loss(logits, y_ph)\n",
    "\n",
    "            #optimizer = tf.train.AdamOptimizer().minimize(loss, name='optimizer')\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(prediction, 1), y_ph)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "        # Code to use of tensorboard\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.scalar_summary('log_loss', loss)\n",
    "            tf.scalar_summary('acc', accuracy)\n",
    "            merged_summary = tf.merge_all_summaries()\n",
    "            \n",
    "    return {\n",
    "        'is_training': is_training,\n",
    "        'x_ph': x_ph,\n",
    "        'y_ph': y_ph,\n",
    "        'prediction': prediction,\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'merged_summary': merged_summary\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_net(layers, session, n_epochs, tb_path='/tmp/tf/', ckpt=None):\n",
    "    tb_path = tb_path + timestamp()\n",
    "    \n",
    "    l = layers\n",
    "    x_ph, y_ph, is_training = l['x_ph'], l['y_ph'], l['is_training']\n",
    "    val_operations = [l['merged_summary'], l['accuracy'], l['loss']]\n",
    "    train_operations = [l['optimizer']] + val_operations\n",
    "    \n",
    "    train_iterator = random_batch_iterator(\n",
    "        mnist.train.images, mnist.train.labels, batch_size=batch_size)\n",
    "    val_iterator = random_batch_iterator(\n",
    "        mnist.validation.images, mnist.validation.labels, batch_size=batch_size)\n",
    "        \n",
    "    train_writer = tf.train.SummaryWriter(tb_path+'/train', session.graph)\n",
    "    val_writer = tf.train.SummaryWriter(tb_path+'/val', session.graph)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    variables_to_restore = slim.get_variables_to_restore(exclude=[\"model/conv1\", \"model/conv2\", \n",
    "                                                                  \"model/model/conv1\", \"model/model/conv2\"])\n",
    "    #print(variables_to_restore)\n",
    "    print([v.name for v in variables_to_restore])\n",
    "    restore = tf.train.Saver(variables_to_restore)\n",
    "    restore.restore(session, ckpt)\n",
    "    #to_drop = False\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        x_batch, y_batch = next(train_iterator)\n",
    "        feed_dict = {x_ph: x_batch, y_ph: y_batch, is_training: True}\n",
    "        _, summary, acc, _ = session.run(train_operations, feed_dict)\n",
    "        train_writer.add_summary(summary, epoch)\n",
    "\n",
    "        x_batch, y_batch = next(val_iterator)\n",
    "        feed_dict = {x_ph: x_batch, y_ph: y_batch, is_training: False}\n",
    "        summary, acc, _ = session.run(val_operations, feed_dict)\n",
    "        val_writer.add_summary(summary, epoch)\n",
    "        #print(acc)\n",
    "                \n",
    "    return best_acc\n",
    "\n",
    "def evaluate_net(layers, session, ckpt):\n",
    "    l = layers\n",
    "    x_ph, y_ph, is_training = l['x_ph'], l['y_ph'], l['is_training']\n",
    "    \n",
    "    test_iterator = iter(test_list)\n",
    "    \n",
    "    n, test_acc = 0, 0.0\n",
    "    variables_to_restore = slim.get_variables_to_restore(exclude=[\"model/conv1/weights\", \"model/conv2/weights\", \n",
    "                                                                  \"model/model/conv1/weights\", \"model/model/conv2/weights\"])\n",
    "    #print(variables_to_restore)\n",
    "    #print([v.name for v in variables_to_restore])\n",
    "    restore = tf.train.Saver(variables_to_restore)\n",
    "    restore.restore(session, ckpt)\n",
    "    start = time.time()\n",
    "    for x_batch, y_batch in test_iterator:\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        feed_dict = {x_ph: x_batch, y_ph: y_batch, is_training: False}\n",
    "        test_acc += l['accuracy'].eval(feed_dict=feed_dict)\n",
    "        n += 1\n",
    "    end = time.time()\n",
    "    test_acc = test_acc / n\n",
    "    return test_acc, end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:34 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:35 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:36 in build_model.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From /home/arsensag/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/logging_ops.py:264 in merge_all_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:34 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:35 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:36 in build_model.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From /home/arsensag/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/logging_ops.py:264 in merge_all_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:34 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:35 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:36 in build_model.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From /home/arsensag/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/logging_ops.py:264 in merge_all_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:34 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:35 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:36 in build_model.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From /home/arsensag/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/logging_ops.py:264 in merge_all_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:34 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:35 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:36 in build_model.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From /home/arsensag/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/logging_ops.py:264 in merge_all_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:34 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:35 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:36 in build_model.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From /home/arsensag/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/logging_ops.py:264 in merge_all_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:34 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:35 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:36 in build_model.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From /home/arsensag/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/logging_ops.py:264 in merge_all_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:34 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:35 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-5-4cdb13f5d69d>:36 in build_model.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From /home/arsensag/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/logging_ops.py:264 in merge_all_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge.\n"
     ]
    }
   ],
   "source": [
    "test_array = []\n",
    "for k in [(2, 4), (3, 4), (3, 6), (3, 8), (4, 6), (4, 8), (8, 8), (8, 16)]:\n",
    "\n",
    "    data = np.load('variables/fd1000_{}_{}.npz'.format(*k))\n",
    "\n",
    "    init_vals = [[np.rollaxis(data['basis1'], 0, 3)[:, :, None, :],\n",
    "                  np.rollaxis(data['basis2'], 0, 3)[:, :, None, :].repeat(32, 2)],\n",
    "                 [data['a1'][None, :, :, :].swapaxes(2, 3),\n",
    "                  data['a2'][None, :, :, :].swapaxes(2, 3).reshape((1, 1, -1, 64))]]\n",
    "\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    layers = build_model(graph, build_cnn_method1, init_vals)\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        els_array = []\n",
    "        for x in range(10):\n",
    "            \n",
    "            test_acc, els = evaluate_net(layers, session, ckpt=original_ckpt_path)\n",
    "            els_array.append(els)\n",
    "    \n",
    "    del data\n",
    "    \n",
    "    #file_name = 'variables/results1000_{}_{}'.format(*k)\n",
    "    test_array.append((test_acc, np.median(els_array)))\n",
    "    \n",
    "    #np.savez(file_name, test_acc = test_acc, els = np.median(els_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=(2,4) (0.68678042763157898, 2.6815844774246216)\n",
      "K=(3,4) (0.77528782894736847, 2.6843863725662231)\n",
      "K=(3,6) (0.84344161184210531, 3.2058632373809814)\n",
      "K=(3,8) (0.93174342105263153, 3.8775361776351929)\n",
      "K=(4,6) (0.95836759868421051, 3.1830161809921265)\n",
      "K=(4,8) (0.97944078947368418, 3.8452098369598389)\n",
      "K=(8,8) (0.98735608552631582, 3.8351763486862183)\n",
      "K=(8,16) (0.98992598684210531, 7.034633994102478)\n"
     ]
    }
   ],
   "source": [
    "for idx, k in enumerate([(2, 4), (3, 4), (3, 6), (3, 8), (4, 6), (4, 8), (8, 8), (8, 16)]):\n",
    "    print(\"K=({},{})\".format(k[0], k[1]), test_array[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 // 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ckpt_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-ba54bd84645b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrestorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrestorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mconv_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ckpt_path' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    restorer = tf.train.Saver()\n",
    "    restorer.restore(session, ckpt_path)\n",
    "    conv_vars = {}\n",
    "    for i in range(n_conv):\n",
    "        for name in ['weights', 'bias']:\n",
    "            full_name = 'conv{}/{}'.format(i+1, name)\n",
    "            conv_vars[full_name] = slim.get_variables(scope='model/'+full_name)[0].eval()\n",
    "            \n",
    "np.savez(variables_file, **conv_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.load(variables_file).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_measurements = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    restorer = tf.train.Saver()\n",
    "    restorer.restore(session, ckpt_path)\n",
    "    mesurements = []\n",
    "    for i in range(n_measurements):\n",
    "        test_acc, els = evaluate_net(layers, session)\n",
    "        mesurements.append(els)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(mesurements, bins=40, range=(0.135, 0.15))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
