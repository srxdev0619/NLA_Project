{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2016/12/11/00:19:38'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data')\n",
    "x_size, y_size = 28, 28\n",
    "n_classes = 10\n",
    "default_collection = 'nodes'\n",
    "\n",
    "def timestamp():\n",
    "    d = datetime.datetime.now()\n",
    "    return d.strftime(\"%Y/%m/%d/%X\")\n",
    "\n",
    "timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch_iterator(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "    assert n == y.shape[0]\n",
    "    \n",
    "    while True:\n",
    "        index = np.random.randint(n, size=batch_size)\n",
    "        x_batch, y_batch = x[index], y[index]\n",
    "        yield x_batch.copy(), y_batch.copy()\n",
    "        \n",
    "def batch_iterator(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "    assert n == y.shape[0]\n",
    "    \n",
    "    for i in range(0, n, batch_size):\n",
    "        x_batch, y_batch = x[i:i+batch_size], y[i:i+batch_size]        \n",
    "        yield x_batch.copy(), y_batch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_cnn(inputs, n_conv, conv_base, conv_mul, conv_size, pool_size, collection=default_collection):\n",
    "    l = inputs\n",
    "    for i in range(n_conv):\n",
    "        n_filters = conv_base * conv_mul ** i\n",
    "        l = slim.conv2d(l, n_filters, [conv_size, conv_size],\n",
    "                        scope='Conv{}'.format(i+1))\n",
    "        l = slim.max_pool2d(l, [pool_size, pool_size], scope='MaxPool{}'.format(i+1))\n",
    "    l = slim.flatten(l)\n",
    "    \n",
    "    l = slim.dropout(l, 0.5, scope='Dropout', outputs_collections=collection)\n",
    "    l = slim.fully_connected(l, 10, activation_fn=None, scope='Output',\n",
    "                             outputs_collections=collection)\n",
    "    return l\n",
    "\n",
    "def build_loss(logits, y_true):\n",
    "    logloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y_true))\n",
    "    return logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "n_conv = 2\n",
    "conv_base = 32\n",
    "conv_mul = 2\n",
    "conv_size = 5\n",
    "pool_size = 2\n",
    "\n",
    "#graph = tf.Graph()\n",
    "#with graph.as_default():\n",
    "x_ph = tf.placeholder(tf.float32, shape=[batch_size, x_size * y_size])\n",
    "x_image = tf.reshape(x_ph, [-1, x_size, y_size, 1])\n",
    "y_ph = tf.placeholder(tf.int64, shape=[batch_size])\n",
    "logits = build_cnn(x_image, n_conv=n_conv, conv_base=conv_base, conv_mul=conv_mul,\n",
    "                           conv_size=conv_size, pool_size=pool_size)\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "loss = build_loss(logits, y_ph)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(prediction, 1), y_ph)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "    # Code to use of tensorboard\n",
    "    #with tf.name_scope('summaries'):\n",
    "    #    tf.scalar_summary('log_loss', loss)\n",
    "    #    tf.scalar_summary('acc', accuracy)\n",
    "    #    merged_summary = tf.merge_all_summaries()\n",
    "\n",
    "#nodes = graph.get_collection(default_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.ops.variables.Variable object at 0x7f0b3a5dfb10>, <tensorflow.python.ops.variables.Variable object at 0x7f0b3a5dfbd0>, <tensorflow.python.ops.variables.Variable object at 0x7f0b3a3f5d10>, <tensorflow.python.ops.variables.Variable object at 0x7f0b3a443cd0>, <tensorflow.python.ops.variables.Variable object at 0x7f0b3a4062d0>, <tensorflow.python.ops.variables.Variable object at 0x7f0b3a406490>]\n",
      "./Mnist_NLA_2_trial.ckpt\n",
      "(5, 5, 1, 32)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_iterator = random_batch_iterator(mnist.train.images, mnist.train.labels, batch_size=batch_size)\n",
    "val_iterator = random_batch_iterator(mnist.validation.images, mnist.validation.labels, batch_size=batch_size)\n",
    "test_iterator = batch_iterator(mnist.test.images, mnist.test.labels, batch_size=batch_size)\n",
    "\n",
    "best_acc = 0.0\n",
    "path = '/tmp/tf/' + timestamp()\n",
    "#variables_to_restore = slim.get_variables_by_name(\"Conv\")\n",
    "#tf.train.import_meta_graph('my-model.meta')\n",
    "#variables_to_restore = slim.get_model_variables()\n",
    "variables_to_restore = slim.get_variables(scope=\"Conv1\")\n",
    "print(variables_to_restore)\n",
    "#restore = tf.train.import_meta_graph('Mnist_NLA_2.ckpt.meta')\n",
    "#print(slim.get_model_variables())\n",
    "print(tf.train.latest_checkpoint('./'))\n",
    "restore = tf.train.Saver(variables_to_restore)\n",
    "with tf.Session() as session:\n",
    "    restore.restore(session, tf.train.latest_checkpoint('./'))\n",
    "    conv1 = slim.get_variables(scope=\"Conv1\")\n",
    "    conv1_arr = conv1[0].eval()\n",
    "    print(conv1_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_acc"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
