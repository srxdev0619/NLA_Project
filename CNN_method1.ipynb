{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2016/12/15/21:04:56'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data')\n",
    "x_size, y_size = 28, 28\n",
    "n_classes = 10\n",
    "\n",
    "n_epochs = 1000\n",
    "ckpt_path = 'models/MNIST_NLA_method1.ckpt'\n",
    "variables_file = './variables/scheme1_fr.npz'\n",
    "activations_file = './variables/scheme1_dr.npz'\n",
    "\n",
    "def timestamp():\n",
    "    d = datetime.datetime.now()\n",
    "    return d.strftime(\"%Y/%m/%d/%X\")\n",
    "\n",
    "timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch_iterator(x, y, *, batch_size):\n",
    "    n = x.shape[0]\n",
    "    assert n == y.shape[0]\n",
    "    \n",
    "    while True:\n",
    "        index = np.random.randint(n, size=batch_size)\n",
    "        x_batch, y_batch = x[index], y[index]\n",
    "        yield x_batch.copy(), y_batch.copy()\n",
    "        \n",
    "def batch_iterator(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "    assert n == y.shape[0]\n",
    "    \n",
    "    for i in range(0, n, batch_size):\n",
    "        x_batch, y_batch = x[i:i+batch_size], y[i:i+batch_size]        \n",
    "        yield x_batch.copy(), y_batch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "test_list = list(batch_iterator(\n",
    "        mnist.test.images, mnist.test.labels, batch_size=batch_size))\n",
    "\n",
    "n_conv = 2\n",
    "conv_base = 32\n",
    "conv_mul = 2\n",
    "conv_size = 5\n",
    "pool_size = 2\n",
    "\n",
    "def build_model(graph, build_cnn):\n",
    "    with graph.as_default():#, graph.device('/cpu:0'):\n",
    "        with tf.variable_scope('model') as vs:\n",
    "            is_training = tf.placeholder(tf.bool)\n",
    "            x_ph = tf.placeholder(tf.float32, shape=[batch_size, x_size * y_size])\n",
    "            x_image = tf.reshape(x_ph, [-1, x_size, y_size, 1])\n",
    "            y_ph = tf.placeholder(tf.int64, shape=[batch_size])\n",
    "\n",
    "            logits = build_cnn(x_image, is_training=is_training, n_conv=n_conv,\n",
    "                               conv_base=conv_base, conv_mul=conv_mul,\n",
    "                               conv_size=conv_size, pool_size=pool_size)\n",
    "\n",
    "            prediction = tf.nn.softmax(logits, name='predictions')\n",
    "\n",
    "            loss = build_loss(logits, y_ph)\n",
    "\n",
    "            optimizer = tf.train.AdamOptimizer().minimize(loss, name='optimizer')\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(prediction, 1), y_ph)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "        # Code to use of tensorboard\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.scalar_summary('log_loss', loss)\n",
    "            tf.scalar_summary('acc', accuracy)\n",
    "            merged_summary = tf.merge_all_summaries()\n",
    "            \n",
    "    return {\n",
    "        'is_training': is_training,\n",
    "        'x_ph': x_ph,\n",
    "        'y_ph': y_ph,\n",
    "        'prediction': prediction,\n",
    "        'loss': loss,\n",
    "        'optimizer': optimizer,\n",
    "        'accuracy': accuracy,\n",
    "        'merged_summary': merged_summary\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_net(layers, session, *, ckpt_path, n_epochs, tb_path='/tmp/tf/'):\n",
    "    tb_path = tb_path + timestamp()\n",
    "    \n",
    "    l = layers\n",
    "    x_ph, y_ph, is_training = l['x_ph'], l['y_ph'], l['is_training']\n",
    "    val_operations = [l['merged_summary'], l['accuracy'], l['loss']]\n",
    "    train_operations = [l['optimizer']] + val_operations\n",
    "\n",
    "    train_iterator = random_batch_iterator(\n",
    "        mnist.train.images, mnist.train.labels, batch_size=batch_size)\n",
    "    val_iterator = random_batch_iterator(\n",
    "        mnist.validation.images, mnist.validation.labels, batch_size=batch_size)\n",
    "        \n",
    "    train_writer = tf.train.SummaryWriter(tb_path+'/train', session.graph)\n",
    "    val_writer = tf.train.SummaryWriter(tb_path+'/val', session.graph)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    best_acc = 0.0\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        x_batch, y_batch = next(train_iterator)\n",
    "        feed_dict = {x_ph: x_batch, y_ph: y_batch, is_training: True}\n",
    "        _, summary, acc, _ = session.run(train_operations, feed_dict)\n",
    "        train_writer.add_summary(summary, epoch)\n",
    "\n",
    "        x_batch, y_batch = next(val_iterator)\n",
    "        feed_dict = {x_ph: x_batch, y_ph: y_batch, is_training: False}\n",
    "        summary, acc, _ = session.run(val_operations, feed_dict)\n",
    "        val_writer.add_summary(summary, epoch)\n",
    "\n",
    "    saver.save(session, ckpt_path)\n",
    "                \n",
    "    return best_acc\n",
    "\n",
    "def evaluate_net(layers, session):\n",
    "    l = layers\n",
    "    x_ph, y_ph, is_training = l['x_ph'], l['y_ph'], l['is_training']\n",
    "    \n",
    "    test_iterator = iter(test_list)\n",
    "    \n",
    "    n, test_acc = 0, 0.0\n",
    "    start = time.time()\n",
    "    for x_batch, y_batch in test_iterator:\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        feed_dict = {x_ph: x_batch, y_ph: y_batch, is_training: False}\n",
    "        test_acc += l['accuracy'].eval(feed_dict=feed_dict)\n",
    "        n += 1\n",
    "    end = time.time()\n",
    "    test_acc = test_acc / n\n",
    "    return test_acc, end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_cnn_method1(inputs, *, is_training, n_conv, conv_base, conv_mul,\n",
    "              conv_size, pool_size):\n",
    "    l = inputs\n",
    "    \n",
    "    for i in range(n_conv):\n",
    "        n_filters = conv_base * conv_mul ** i\n",
    "        M = n_filters // 2\n",
    "        \n",
    "        batch_size, w, h, in_channels = l.get_shape()\n",
    "        with tf.variable_scope('conv{}'.format(i+1)):\n",
    "            f = tf.get_variable('basis', shape=[conv_size, conv_size, in_channels, M])\n",
    "            l = tf.nn.depthwise_conv2d(l, f, [1, 1, 1, 1], padding='SAME', name='conv')\n",
    "            l = slim.conv2d(l, n_filters,kernel_size=[1, 1], padding='SAME',\n",
    "                            scope='a'.format(i+1))\n",
    "        l = slim.max_pool2d(l, [pool_size, pool_size], scope='maxpool{}'.format(i+1))\n",
    "    l = slim.flatten(l)\n",
    "    \n",
    "    l = slim.dropout(l, 0.5, scope='dropout', is_training=is_training)\n",
    "    l = slim.fully_connected(l, 10, activation_fn=None, scope='output')\n",
    "    return l\n",
    "\n",
    "def build_loss(logits, y_true):\n",
    "    logloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y_true),\n",
    "                             name='logloss')\n",
    "    return logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 28, 28, 16)\n",
      "(512, 28, 28, 32)\n",
      "(512, 14, 14, 1024)\n",
      "(512, 14, 14, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.99167351973684215, 0.9134867191314697)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "layers = build_model(graph, build_cnn_method1)\n",
    "with tf.Session(graph=graph) as session:\n",
    "    train_net(layers, session, n_epochs=n_epochs, ckpt_path=ckpt_path)\n",
    "    test_acc, els = evaluate_net(layers, session)\n",
    "\n",
    "test_acc, els"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ab47f3462710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmesurements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_measurements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmesurements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-dabd256d0546>\u001b[0m in \u001b[0;36mevaluate_net\u001b[0;34m(layers, session)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3631\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3633\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_measurements = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    restorer = tf.train.Saver()\n",
    "    restorer.restore(session, tf.train.latest_checkpoint(ckpt_dir))\n",
    "    mesurements = []\n",
    "    for i in range(n_measurements):\n",
    "        test_acc, els = evaluate_net(layers, session)\n",
    "        mesurements.append(els)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.,   0.,   1.,   0.,   2.,   4.,   6.,   4.,   7.,   6.,   6.,\n",
       "          8.,  11.,   8.,   9.,  11.,   9.,   2.,   1.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.]),\n",
       " array([ 0.14   ,  0.14025,  0.1405 ,  0.14075,  0.141  ,  0.14125,\n",
       "         0.1415 ,  0.14175,  0.142  ,  0.14225,  0.1425 ,  0.14275,\n",
       "         0.143  ,  0.14325,  0.1435 ,  0.14375,  0.144  ,  0.14425,\n",
       "         0.1445 ,  0.14475,  0.145  ,  0.14525,  0.1455 ,  0.14575,\n",
       "         0.146  ,  0.14625,  0.1465 ,  0.14675,  0.147  ,  0.14725,\n",
       "         0.1475 ,  0.14775,  0.148  ,  0.14825,  0.1485 ,  0.14875,\n",
       "         0.149  ,  0.14925,  0.1495 ,  0.14975,  0.15   ]),\n",
       " <a list of 40 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAFkCAYAAABxWwLDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAJJim+LkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4b8a80d128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mesurements, bins=40, range=(0.14, 0.15))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
