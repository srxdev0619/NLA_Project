{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2016/12/15/20:44:53'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data')\n",
    "x_size, y_size = 28, 28\n",
    "n_classes = 10\n",
    "\n",
    "n_epochs = 1000\n",
    "ckpt_path = './models/MNIST_NLA_vanilla.ckpt'\n",
    "variables_file = './variables/scheme1_fr.npz'\n",
    "activations_file = './variables/scheme1_dr.npz'\n",
    "\n",
    "def timestamp():\n",
    "    d = datetime.datetime.now()\n",
    "    return d.strftime(\"%Y/%m/%d/%X\")\n",
    "\n",
    "timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch_iterator(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "    assert n == y.shape[0]\n",
    "    \n",
    "    while True:\n",
    "        index = np.random.randint(n, size=batch_size)\n",
    "        x_batch, y_batch = x[index], y[index]\n",
    "        yield x_batch.copy(), y_batch.copy()\n",
    "        \n",
    "def batch_iterator(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "    assert n == y.shape[0]\n",
    "    \n",
    "    for i in range(0, n, batch_size):\n",
    "        x_batch, y_batch = x[i:i+batch_size], y[i:i+batch_size]        \n",
    "        yield x_batch.copy(), y_batch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_cnn(inputs, is_training, n_conv, conv_base, conv_mul,\n",
    "              conv_size, pool_size):\n",
    "    l = inputs\n",
    "    for i in range(n_conv):\n",
    "        n_filters = conv_base * conv_mul ** i\n",
    "        l = slim.conv2d(l, n_filters, [conv_size, conv_size],\n",
    "                        scope='conv{}'.format(i+1), is_training=is_training)\n",
    "        l = slim.max_pool2d(l, [pool_size, pool_size], scope='maxpool{}'.format(i+1), is_training=is_training)\n",
    "    l = slim.flatten(l)\n",
    "    \n",
    "    l = slim.dropout(l, 0.5, scope='dropout', is_training=is_training)\n",
    "    l = slim.fully_connected(l, 10, activation_fn=None, scope='logits', is_training=is_training)\n",
    "    return l\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def conv_layer(prev_layer, C, M, N, scope=''):\n",
    "    var_name = scope + \"basis\"\n",
    "    s = tf.get_variable(name=var_name, shape=[5,5,C,C*M])\n",
    "    new_activate = tf.nn.depthwise_conv2d(prev_layer, s, [1,1,1,1], padding=\"SAME\",name = (scope + \"conv\"))\n",
    "    new_activate = slim.conv2d(new_activate, N, [1,1], scope=(scope + \"a\"))\n",
    "    return new_activate\n",
    "\n",
    "def build_mod_cnn(inputs, is_training, n_conv, conv_base, conv_mul,\n",
    "              conv_size, pool_size):\n",
    "    l = inputs\n",
    "    input_c = [1,32]\n",
    "    for i in range(n_conv):\n",
    "        n_filters = conv_base * conv_mul ** i\n",
    "        l = conv_layer(l, input_c[i], 16, n_filters, scope='conv{}'.format(i+1))\n",
    "        l = slim.max_pool2d(l, [pool_size, pool_size], scope='maxpool{}'.format(i+1))\n",
    "    l = slim.flatten(l)\n",
    "    \n",
    "    l = slim.dropout(l, 0.5, scope='dropout', is_training=is_training)\n",
    "    l = slim.fully_connected(l, 10, activation_fn=None, scope='logits', trainable=True)\n",
    "    return l\n",
    "\n",
    "def build_loss(logits, y_true):\n",
    "    logloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y_true),\n",
    "                             name='logloss')\n",
    "    return logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "test_list = list(batch_iterator(\n",
    "        mnist.test.images, mnist.test.labels, batch_size=batch_size))\n",
    "\n",
    "n_conv = 2\n",
    "conv_base = 32\n",
    "conv_mul = 2\n",
    "conv_size = 5\n",
    "pool_size = 2\n",
    "\n",
    "def build_model(graph, build_cnn):\n",
    "    with graph.as_default():#, graph.device('/cpu:0'):\n",
    "        with tf.variable_scope('model') as vs:\n",
    "            is_training = tf.placeholder(tf.bool)\n",
    "            x_ph = tf.placeholder(tf.float32, shape=[batch_size, x_size * y_size])\n",
    "            x_image = tf.reshape(x_ph, [-1, x_size, y_size, 1])\n",
    "            y_ph = tf.placeholder(tf.int64, shape=[batch_size])\n",
    "            print(\"BRK1\")\n",
    "            logits = build_cnn(x_image, is_training=is_training, n_conv=n_conv,\n",
    "                               conv_base=conv_base, conv_mul=conv_mul,\n",
    "                               conv_size=conv_size, pool_size=pool_size)\n",
    "            print(\"BRK2\")\n",
    "            prediction = tf.nn.softmax(logits, name='predictions')\n",
    "\n",
    "            loss = build_loss(logits, y_ph)\n",
    "\n",
    "            optimizer = tf.train.AdamOptimizer().minimize(loss, name='optimizer')\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(prediction, 1), y_ph)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "        # Code to use of tensorboard\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.scalar_summary('log_loss', loss)\n",
    "            tf.scalar_summary('acc', accuracy)\n",
    "            merged_summary = tf.merge_all_summaries()\n",
    "            \n",
    "    return {\n",
    "        'is_training': is_training,\n",
    "        'x_ph': x_ph,\n",
    "        'y_ph': y_ph,\n",
    "        'prediction': prediction,\n",
    "        'loss': loss,\n",
    "        'optimizer': optimizer,\n",
    "        'accuracy': accuracy,\n",
    "        'merged_summary': merged_summary\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_net(layers, session, n_epochs, ckpt_path, tb_path='/tmp/tf/', ckpt=None):\n",
    "    tb_path = tb_path + timestamp()\n",
    "    \n",
    "    l = layers\n",
    "    x_ph, y_ph, is_training = l['x_ph'], l['y_ph'], l['is_training']\n",
    "    val_operations = [l['merged_summary'], l['accuracy'], l['loss']]\n",
    "    train_operations = [l['optimizer']] + val_operations\n",
    "    \n",
    "    train_iterator = random_batch_iterator(\n",
    "        mnist.train.images, mnist.train.labels, batch_size=batch_size)\n",
    "    val_iterator = random_batch_iterator(\n",
    "        mnist.validation.images, mnist.validation.labels, batch_size=batch_size)\n",
    "        \n",
    "    train_writer = tf.train.SummaryWriter(tb_path+'/train', session.graph)\n",
    "    val_writer = tf.train.SummaryWriter(tb_path+'/val', session.graph)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    best_acc = 0.0\n",
    "    to_drop = True\n",
    "    if ckpt:\n",
    "        variables_to_restore = slim.get_variables_to_restore(exclude=[\"conv1\", \"conv2\"])\n",
    "        restore = tf.train.Saver(variables_to_restore)\n",
    "        restore.restore(session, ckpt)\n",
    "        to_drop = False\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        x_batch, y_batch = next(train_iterator)\n",
    "        feed_dict = {x_ph: x_batch, y_ph: y_batch, is_training: to_drop}\n",
    "        _, summary, acc, _ = session.run(train_operations, feed_dict)\n",
    "        train_writer.add_summary(summary, epoch)\n",
    "\n",
    "        x_batch, y_batch = next(val_iterator)\n",
    "        feed_dict = {x_ph: x_batch, y_ph: y_batch, is_training: False}\n",
    "        summary, acc, _ = session.run(val_operations, feed_dict)\n",
    "        val_writer.add_summary(summary, epoch)\n",
    "        print(acc)\n",
    "\n",
    "    saver.save(session, ckpt_path)\n",
    "                \n",
    "    return best_acc\n",
    "\n",
    "def evaluate_net(layers, session):\n",
    "    l = layers\n",
    "    x_ph, y_ph, is_training = l['x_ph'], l['y_ph'], l['is_training']\n",
    "    \n",
    "    test_iterator = iter(test_list)\n",
    "    \n",
    "    n, test_acc = 0, 0.0\n",
    "    start = time.time()\n",
    "    for x_batch, y_batch in test_iterator:\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        feed_dict = {x_ph: x_batch, y_ph: y_batch, is_training: False}\n",
    "        test_acc += l['accuracy'].eval(feed_dict=feed_dict)\n",
    "        n += 1\n",
    "    end = time.time()\n",
    "    test_acc = test_acc / n\n",
    "    return test_acc, end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRK1\n",
      "BRK2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[512,14,14,16384]\n\t [[Node: model/gradients/model/conv2a/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](model/gradients/model/conv2a/convolution_grad/Shape, model/conv2a/weights/read, model/gradients/model/conv2a/BiasAdd_grad/tuple/control_dependency)]]\n\nCaused by op u'model/gradients/model/conv2a/convolution_grad/Conv2DBackpropInput', defined at:\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-6b6bc3a39f18>\", line 2, in <module>\n    layers = build_model(graph, build_mod_cnn)\n  File \"<ipython-input-5-b383c783d91a>\", line 27, in build_model\n    optimizer = tf.train.AdamOptimizer().minimize(loss, name='optimizer')\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 269, in minimize\n    grad_loss=grad_loss)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 335, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 482, in gradients\n    in_grads = grad_fn(op, *out_grads)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/nn_grad.py\", line 342, in _Conv2DGrad\n    op.get_attr(\"data_format\")),\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 489, in conv2d_backprop_input\n    data_format=data_format, name=name)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'model/conv2a/convolution', defined at:\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-7-6b6bc3a39f18>\", line 2, in <module>\n    layers = build_model(graph, build_mod_cnn)\n  File \"<ipython-input-5-b383c783d91a>\", line 21, in build_model\n    conv_size=conv_size, pool_size=pool_size)\n  File \"<ipython-input-4-c7186ad34dee>\", line 30, in build_mod_cnn\n    l = conv_layer(l, input_c[i], 16, n_filters, scope='conv{}'.format(i+1))\n  File \"<ipython-input-4-c7186ad34dee>\", line 21, in conv_layer\n    new_activate = slim.conv2d(new_activate, N, [1,1], scope=scope + \"a\")\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 177, in func_with_args\n    return func(*args, **current_args)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 846, in convolution\n    data_format=data_format)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 640, in convolution\n    op=op)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 309, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 632, in op\n    name=name)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 130, in _non_atrous_convolution\n    name=name)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[512,14,14,16384]\n\t [[Node: model/gradients/model/conv2a/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](model/gradients/model/conv2a/convolution_grad/Shape, model/conv2a/weights/read, model/gradients/model/conv2a/BiasAdd_grad/tuple/control_dependency)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6b6bc3a39f18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_mod_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m###Change THIS!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-00cde180d0e6>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(layers, session, n_epochs, ckpt_path, tb_path, ckpt)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mto_drop\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_operations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[512,14,14,16384]\n\t [[Node: model/gradients/model/conv2a/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](model/gradients/model/conv2a/convolution_grad/Shape, model/conv2a/weights/read, model/gradients/model/conv2a/BiasAdd_grad/tuple/control_dependency)]]\n\nCaused by op u'model/gradients/model/conv2a/convolution_grad/Conv2DBackpropInput', defined at:\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-6b6bc3a39f18>\", line 2, in <module>\n    layers = build_model(graph, build_mod_cnn)\n  File \"<ipython-input-5-b383c783d91a>\", line 27, in build_model\n    optimizer = tf.train.AdamOptimizer().minimize(loss, name='optimizer')\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 269, in minimize\n    grad_loss=grad_loss)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 335, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 482, in gradients\n    in_grads = grad_fn(op, *out_grads)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/nn_grad.py\", line 342, in _Conv2DGrad\n    op.get_attr(\"data_format\")),\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 489, in conv2d_backprop_input\n    data_format=data_format, name=name)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'model/conv2a/convolution', defined at:\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-7-6b6bc3a39f18>\", line 2, in <module>\n    layers = build_model(graph, build_mod_cnn)\n  File \"<ipython-input-5-b383c783d91a>\", line 21, in build_model\n    conv_size=conv_size, pool_size=pool_size)\n  File \"<ipython-input-4-c7186ad34dee>\", line 30, in build_mod_cnn\n    l = conv_layer(l, input_c[i], 16, n_filters, scope='conv{}'.format(i+1))\n  File \"<ipython-input-4-c7186ad34dee>\", line 21, in conv_layer\n    new_activate = slim.conv2d(new_activate, N, [1,1], scope=scope + \"a\")\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 177, in func_with_args\n    return func(*args, **current_args)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 846, in convolution\n    data_format=data_format)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 640, in convolution\n    op=op)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 309, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 632, in op\n    name=name)\n  File \"/home/aaragon/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 130, in _non_atrous_convolution\n    name=name)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[512,14,14,16384]\n\t [[Node: model/gradients/model/conv2a/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](model/gradients/model/conv2a/convolution_grad/Shape, model/conv2a/weights/read, model/gradients/model/conv2a/BiasAdd_grad/tuple/control_dependency)]]\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "layers = build_model(graph, build_mod_cnn)\n",
    "with tf.Session(graph=graph) as session:\n",
    "    train_net(layers, session, n_epochs=n_epochs, ckpt_path=ckpt_path, ckpt=None)###Change THIS!!!\n",
    "    test_acc, els = evaluate_net(layers, session)\n",
    "\n",
    "test_acc, els"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    restorer = tf.train.Saver()\n",
    "    restorer.restore(session, ckpt_path)\n",
    "    conv_vars = {}\n",
    "    for i in range(n_conv):\n",
    "        for name in ['weights', 'bias']:\n",
    "            full_name = 'conv{}/{}'.format(i+1, name)\n",
    "            conv_vars[full_name] = slim.get_variables(scope='model/'+full_name)[0].eval()\n",
    "            \n",
    "np.savez(variables_file, **conv_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.load(variables_file).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_measurements = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    restorer = tf.train.Saver()\n",
    "    restorer.restore(session, ckpt_path)\n",
    "    mesurements = []\n",
    "    for i in range(n_measurements):\n",
    "        test_acc, els = evaluate_net(layers, session)\n",
    "        mesurements.append(els)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(mesurements, bins=40, range=(0.135, 0.15))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
