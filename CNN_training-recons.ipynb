{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2016/12/15/16:53:17'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data')\n",
    "x_size, y_size = 28, 28\n",
    "n_classes = 10\n",
    "\n",
    "n_epochs = 1000\n",
    "ckpt_path = './models/MNIST_NLA_vanilla.ckpt'\n",
    "variables_file = './variables/scheme1_fr.npz'\n",
    "activations_file = './variables/scheme1_dr.npz'\n",
    "\n",
    "def timestamp():\n",
    "    d = datetime.datetime.now()\n",
    "    return d.strftime(\"%Y/%m/%d/%X\")\n",
    "\n",
    "timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch_iterator(x, y, *, batch_size):\n",
    "    n = x.shape[0]\n",
    "    assert n == y.shape[0]\n",
    "    \n",
    "    while True:\n",
    "        index = np.random.randint(n, size=batch_size)\n",
    "        x_batch, y_batch = x[index], y[index]\n",
    "        yield x_batch.copy(), y_batch.copy()\n",
    "        \n",
    "def batch_iterator(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "    assert n == y.shape[0]\n",
    "    \n",
    "    for i in range(0, n, batch_size):\n",
    "        x_batch, y_batch = x[i:i+batch_size], y[i:i+batch_size]        \n",
    "        yield x_batch.copy(), y_batch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_cnn(inputs, *, is_training, n_conv, conv_base, conv_mul,\n",
    "              conv_size, pool_size):\n",
    "    l = inputs\n",
    "    for i in range(n_conv):\n",
    "        n_filters = conv_base * conv_mul ** i\n",
    "        l = slim.conv2d(l, n_filters, [conv_size, conv_size],\n",
    "                        scope='conv{}'.format(i+1), is_training=is_training)\n",
    "        l = slim.max_pool2d(l, [pool_size, pool_size], scope='maxpool{}'.format(i+1), is_training=is_training)\n",
    "    l = slim.flatten(l)\n",
    "    \n",
    "    l = slim.dropout(l, 0.5, scope='dropout', is_training=is_training)\n",
    "    l = slim.fully_connected(l, 10, activation_fn=None, scope='logits', is_training=is_training)\n",
    "    return l\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def conv_layer(prev_layer, C, M, N, scope=''):\n",
    "    a = tf.Variable(tf.truncated_normal([N,C,M], stddev=0.1), name= scope + \"/\" + \"a\")\n",
    "    s = tf.Variable(tf.truncated_normal([5,5,1,M], stddev=0.1), name= scope + \"/\" +\"basis\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[N]), name=scope + \"/\" +\"bias\")\n",
    "    w = []\n",
    "    for i in range(N):\n",
    "        temp_w = []\n",
    "        for c in range(C):\n",
    "            temp_w_c = []\n",
    "            for j in range(M):\n",
    "                temp_w_c.append(a[i,c,j]*s[:,:,:,j])\n",
    "            temp_w.append(tf.reshape(tf.add_n(temp_w_c), [5,5,1,1]))\n",
    "        w.append(tf.concat(2, temp_w))\n",
    "    w = tf.concat(3,w)\n",
    "    conv1_pred = tf.nn.relu(conv2d(prev_layer, w) + b)\n",
    "    return conv1_pred,s\n",
    "\n",
    "def build_mod_cnn(inputs, *, is_training, n_conv, conv_base, conv_mul,\n",
    "              conv_size, pool_size):\n",
    "    l = inputs\n",
    "    input_c [1,32]\n",
    "    for i in range(n_conv):\n",
    "        n_filters = conv_base * conv_mul ** i\n",
    "        l = conv_layer(l, input_c[i], 16, n_filters, scope='conv{}'.format(i+1))[0]\n",
    "        l = slim.max_pool2d(l, [pool_size, pool_size], scope='maxpool{}'.format(i+1), is_training=is_training)\n",
    "    l = slim.flatten(l)\n",
    "    \n",
    "    l = slim.dropout(l, 0.5, scope='dropout', is_training=is_training)\n",
    "    l = slim.fully_connected(l, 10, activation_fn=None, scope='logits', is_training=is_training)\n",
    "    return l\n",
    "\n",
    "def build_loss(logits, y_true):\n",
    "    logloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y_true),\n",
    "                             name='logloss')\n",
    "    return logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "test_list = list(batch_iterator(\n",
    "        mnist.test.images, mnist.test.labels, batch_size=batch_size))\n",
    "\n",
    "n_conv = 2\n",
    "conv_base = 32\n",
    "conv_mul = 2\n",
    "conv_size = 5\n",
    "pool_size = 2\n",
    "\n",
    "def build_model(graph, build_cnn):\n",
    "    with graph.as_default():#, graph.device('/cpu:0'):\n",
    "        with tf.variable_scope('model') as vs:\n",
    "            is_training = tf.placeholder(tf.bool)\n",
    "            x_ph = tf.placeholder(tf.float32, shape=[batch_size, x_size * y_size])\n",
    "            x_image = tf.reshape(x_ph, [-1, x_size, y_size, 1])\n",
    "            y_ph = tf.placeholder(tf.int64, shape=[batch_size])\n",
    "\n",
    "            logits = build_mod_cnn(x_image, is_training=is_training, n_conv=n_conv,\n",
    "                               conv_base=conv_base, conv_mul=conv_mul,\n",
    "                               conv_size=conv_size, pool_size=pool_size)\n",
    "\n",
    "            prediction = tf.nn.softmax(logits, name='predictions')\n",
    "\n",
    "            loss = build_loss(logits, y_ph)\n",
    "\n",
    "            optimizer = tf.train.AdamOptimizer().minimize(loss, name='optimizer')\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(prediction, 1), y_ph)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "        # Code to use of tensorboard\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.scalar_summary('log_loss', loss)\n",
    "            tf.scalar_summary('acc', accuracy)\n",
    "            merged_summary = tf.merge_all_summaries()\n",
    "            \n",
    "    return {\n",
    "        'is_training': is_training,\n",
    "        'x_ph': x_ph,\n",
    "        'y_ph': y_ph,\n",
    "        'prediction': prediction,\n",
    "        'loss': loss,\n",
    "        'optimizer': optimizer,\n",
    "        'accuracy': accuracy,\n",
    "        'merged_summary': merged_summary\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_net(layers, session, *, n_epochs, ckpt_path, tb_path='/tmp/tf/', ckpt=None):\n",
    "    tb_path = tb_path + timestamp()\n",
    "    \n",
    "    l = layers\n",
    "    x_ph, y_ph, is_training = l['x_ph'], l['y_ph'], l['is_training']\n",
    "    val_operations = [l['merged_summary'], l['accuracy'], l['loss']]\n",
    "    train_operations = [l['optimizer']] + val_operations\n",
    "\n",
    "    train_iterator = random_batch_iterator(\n",
    "        mnist.train.images, mnist.train.labels, batch_size=batch_size)\n",
    "    val_iterator = random_batch_iterator(\n",
    "        mnist.validation.images, mnist.validation.labels, batch_size=batch_size)\n",
    "        \n",
    "    train_writer = tf.train.SummaryWriter(tb_path+'/train', session.graph)\n",
    "    val_writer = tf.train.SummaryWriter(tb_path+'/val', session.graph)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    best_acc = 0.0\n",
    "    if ckpt:\n",
    "        variables_to_restore = slim.get_variables_to_restore(exclude=[\"conv1\", \"conv2\"])\n",
    "        restore = tf.train.Saver(variables_to_restore)\n",
    "        restore.restore(session, ckpt)\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        x_batch, y_batch = next(train_iterator)\n",
    "        feed_dict = {x_ph: x_batch, y_ph: y_batch, is_training: True}\n",
    "        _, summary, acc, _ = session.run(train_operations, feed_dict)\n",
    "        train_writer.add_summary(summary, epoch)\n",
    "\n",
    "        x_batch, y_batch = next(val_iterator)\n",
    "        feed_dict = {x_ph: x_batch, y_ph: y_batch, is_training: False}\n",
    "        summary, acc, _ = session.run(val_operations, feed_dict)\n",
    "        val_writer.add_summary(summary, epoch)\n",
    "\n",
    "    saver.save(session, ckpt_path)\n",
    "                \n",
    "    return best_acc\n",
    "\n",
    "def evaluate_net(layers, session):\n",
    "    l = layers\n",
    "    x_ph, y_ph, is_training = l['x_ph'], l['y_ph'], l['is_training']\n",
    "    \n",
    "    test_iterator = iter(test_list)\n",
    "    \n",
    "    n, test_acc = 0, 0.0\n",
    "    start = time.time()\n",
    "    for x_batch, y_batch in test_iterator:\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        feed_dict = {x_ph: x_batch, y_ph: y_batch, is_training: False}\n",
    "        test_acc += l['accuracy'].eval(feed_dict=feed_dict)\n",
    "        n += 1\n",
    "    end = time.time()\n",
    "    test_acc = test_acc / n\n",
    "    return test_acc, end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99187911184210531, 0.14334893226623535)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "layers = build_model(graph, build_cnn)\n",
    "with tf.Session(graph=graph) as session:\n",
    "    train_net(layers, session, n_epochs=n_epochs, ckpt_path=ckpt_path, ckpt=None)###Change THIS!!!\n",
    "    test_acc, els = evaluate_net(layers, session)\n",
    "\n",
    "test_acc, els"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    restorer = tf.train.Saver()\n",
    "    restorer.restore(session, ckpt_path)\n",
    "    conv_vars = {}\n",
    "    for i in range(n_conv):\n",
    "        for name in ['weights', 'bias']:\n",
    "            full_name = 'conv{}/{}'.format(i+1, name)\n",
    "            conv_vars[full_name] = slim.get_variables(scope='model/'+full_name)[0].eval()\n",
    "            \n",
    "np.savez(variables_file, **conv_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1/weights', 'conv2/bias', 'conv2/weights', 'conv1/bias']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(variables_file).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_measurements = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    restorer = tf.train.Saver()\n",
    "    restorer.restore(session, ckpt_path)\n",
    "    mesurements = []\n",
    "    for i in range(n_measurements):\n",
    "        test_acc, els = evaluate_net(layers, session)\n",
    "        mesurements.append(els)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.,   0.,   0.,   0.,   1.,   1.,   0.,   0.,   3.,   4.,   5.,\n",
       "          4.,   8.,  10.,  15.,  17.,   8.,  12.,   4.,   2.,   2.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   1.,   0.,   0.]),\n",
       " array([ 0.135   ,  0.135375,  0.13575 ,  0.136125,  0.1365  ,  0.136875,\n",
       "         0.13725 ,  0.137625,  0.138   ,  0.138375,  0.13875 ,  0.139125,\n",
       "         0.1395  ,  0.139875,  0.14025 ,  0.140625,  0.141   ,  0.141375,\n",
       "         0.14175 ,  0.142125,  0.1425  ,  0.142875,  0.14325 ,  0.143625,\n",
       "         0.144   ,  0.144375,  0.14475 ,  0.145125,  0.1455  ,  0.145875,\n",
       "         0.14625 ,  0.146625,  0.147   ,  0.147375,  0.14775 ,  0.148125,\n",
       "         0.1485  ,  0.148875,  0.14925 ,  0.149625,  0.15    ]),\n",
       " <a list of 40 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAFkCAYAAABxWwLDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc679779cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mesurements, bins=40, range=(0.135, 0.15))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
