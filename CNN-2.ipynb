{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2016/12/10/23:44:40'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data')\n",
    "x_size, y_size = 28, 28\n",
    "n_classes = 10\n",
    "default_collection = 'nodes'\n",
    "\n",
    "def timestamp():\n",
    "    d = datetime.datetime.now()\n",
    "    return d.strftime(\"%Y/%m/%d/%X\")\n",
    "\n",
    "timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch_iterator(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "    assert n == y.shape[0]\n",
    "    \n",
    "    while True:\n",
    "        index = np.random.randint(n, size=batch_size)\n",
    "        x_batch, y_batch = x[index], y[index]\n",
    "        yield x_batch.copy(), y_batch.copy()\n",
    "        \n",
    "def batch_iterator(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "    assert n == y.shape[0]\n",
    "    \n",
    "    for i in range(0, n, batch_size):\n",
    "        x_batch, y_batch = x[i:i+batch_size], y[i:i+batch_size]        \n",
    "        yield x_batch.copy(), y_batch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_cnn(inputs, n_conv, conv_base, conv_mul, conv_size, pool_size, collection=default_collection):\n",
    "    l = inputs\n",
    "    for i in range(n_conv):\n",
    "        n_filters = conv_base * conv_mul ** i\n",
    "        l = slim.conv2d(l, n_filters, [conv_size, conv_size],\n",
    "                        scope='Conv{}'.format(i+1))\n",
    "        l = slim.max_pool2d(l, [pool_size, pool_size], scope='MaxPool{}'.format(i+1))\n",
    "    l = slim.flatten(l)\n",
    "    \n",
    "    l = slim.dropout(l, keep_prob, scope='Dropout', outputs_collections=collection)\n",
    "    l = slim.fully_connected(l, 10, activation_fn=None, scope='Output',\n",
    "                             outputs_collections=collection)\n",
    "    return l\n",
    "\n",
    "def build_loss(logits, y_true):\n",
    "    logloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y_true))\n",
    "    return logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "n_conv = 2\n",
    "conv_base = 32\n",
    "conv_mul = 2\n",
    "conv_size = 5\n",
    "pool_size = 2\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x_ph = tf.placeholder(tf.float32, shape=[batch_size, x_size * y_size])\n",
    "    x_image = tf.reshape(x_ph, [-1, x_size, y_size, 1])\n",
    "    y_ph = tf.placeholder(tf.int64, shape=[batch_size])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    logits = build_cnn(x_image, n_conv=n_conv, conv_base=conv_base, conv_mul=conv_mul,\n",
    "                           conv_size=conv_size, pool_size=pool_size)\n",
    "\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    loss = build_loss(logits, y_ph)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), y_ph)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "    # Code to use of tensorboard\n",
    "    #with tf.name_scope('summaries'):\n",
    "    #    tf.scalar_summary('log_loss', loss)\n",
    "    #    tf.scalar_summary('acc', accuracy)\n",
    "    #    merged_summary = tf.merge_all_summaries()\n",
    "\n",
    "#nodes = graph.get_collection(default_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Current Validation accuracy is: 25.20%\n",
      "Current Validation accuracy is: 36.52%\n",
      "Current Validation accuracy is: 37.11%\n",
      "Current Validation accuracy is: 41.21%\n",
      "Current Validation accuracy is: 54.69%\n",
      "Current Validation accuracy is: 62.50%\n",
      "Current Validation accuracy is: 61.91%\n",
      "Current Validation accuracy is: 64.84%\n",
      "Current Validation accuracy is: 64.45%\n",
      "Current Validation accuracy is: 65.04%\n",
      "The test accuracy is: 67.23%\n",
      "WARNING:tensorflow:From <ipython-input-8-204a7d895c7d>:43 in <module>.: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2016-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "[u'Conv1/weights:0', u'Conv1/biases:0', u'Conv2/weights:0', u'Conv2/biases:0', u'Output/weights:0', u'Output/biases:0', u'beta1_power:0', u'beta2_power:0', u'Conv1/weights/Adam:0', u'Conv1/weights/Adam_1:0', u'Conv1/biases/Adam:0', u'Conv1/biases/Adam_1:0', u'Conv2/weights/Adam:0', u'Conv2/weights/Adam_1:0', u'Conv2/biases/Adam:0', u'Conv2/biases/Adam_1:0', u'Output/weights/Adam:0', u'Output/weights/Adam_1:0', u'Output/biases/Adam:0', u'Output/biases/Adam_1:0']\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "train_iterator = random_batch_iterator(mnist.train.images, mnist.train.labels, batch_size=batch_size)\n",
    "val_iterator = random_batch_iterator(mnist.validation.images, mnist.validation.labels, batch_size=batch_size)\n",
    "test_iterator = batch_iterator(mnist.test.images, mnist.test.labels, batch_size=batch_size)\n",
    "\n",
    "best_acc = 0.0\n",
    "path = '/tmp/tf/' + timestamp()\n",
    "with tf.Session(graph=graph) as session:\n",
    "    saver = tf.train.Saver()\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    #train_writer = tf.train.SummaryWriter(\n",
    "    #    path+'/train', session.graph)\n",
    "    #val_writer = tf.train.SummaryWriter(\n",
    "    #    path+'/val', session.graph)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        x_batch, y_batch = next(train_iterator)\n",
    "        _, acc, l = session.run([optimizer, accuracy, loss],\n",
    "                                         feed_dict={x_ph: x_batch, y_ph: y_batch, keep_prob:0.5})\n",
    "        #train_writer.add_summary(summary, epoch)\n",
    "        \n",
    "        x_batch, y_batch = next(val_iterator)\n",
    "        acc, l = session.run([accuracy, loss],\n",
    "                                      feed_dict={x_ph: x_batch, y_ph: y_batch, keep_prob:1.0})\n",
    "        #val_writer.add_summary(summary, epoch)\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            saver.save(session,\"Mnist_NLA_2_trial.ckpt\")\n",
    "        print(\"Current Validation accuracy is: {:<4.2%}\".format(acc))\n",
    "        \n",
    "    test_acc = 0\n",
    "    n = 0\n",
    "    for x_batch, y_batch in test_iterator:\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        test_acc += accuracy.eval(feed_dict={x_ph: x_batch, y_ph: y_batch, keep_prob:1.0})\n",
    "        n += 1\n",
    "    test_acc = test_acc / n\n",
    "    print(\"The test accuracy is: {:<4.2%}\".format(test_acc))\n",
    "    var_names = [v.name for v in tf.all_variables()]\n",
    "    print(var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
