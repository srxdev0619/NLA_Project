{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshape in function using scipy optimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cvx\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# objective function to minimize:\n",
    "# Sum (W - Sum a*s)\n",
    "\n",
    "N = 64 #number of filters\n",
    "M = 18\n",
    "\n",
    "#filter sizes:\n",
    "\n",
    "n = 5\n",
    "m = 3\n",
    "\n",
    "#generate random sequence of filters\n",
    "W = []\n",
    "for i in range(N):\n",
    "    W.append(np.random.rand(n,m))\n",
    "\n",
    "\n",
    "#definition of the objective function\n",
    "def fun(params, W, n, m, N, M):\n",
    "\n",
    "    #recovering the original structure of parameters\n",
    "    A = params[:N*M].reshape((N,M))\n",
    "    X = params[N*M:].reshape((M,n,m))\n",
    "\n",
    "    #print(\"A.Shape: \", A.shape)\n",
    "    #print(\"X.Shape: \", X.shape)\n",
    "    \n",
    "    res = 0\n",
    "    for i in range(N):\n",
    "        \n",
    "        # calculating the linear combination of matrices\n",
    "        a_X = 0\n",
    "        for j in range(M):\n",
    "            a_X += A[i,j]*X[j,:,:]\n",
    "            #print(\"-\"*5,j)\n",
    "            \n",
    "        # calculating sum of\n",
    "        res += np.linalg.norm(W[i] - a_X, 2)\n",
    "        \n",
    "    return res\n",
    "\n",
    "\n",
    "shape = (n,m)\n",
    "params = []\n",
    "\n",
    "#initializing coefficients for linear combination\n",
    "params = np.random.rand(N*M+M*n*m)  # N*M for lc coefiicients and m*n*M for matrix weights\n",
    "\n",
    "res = scipy.optimize.minimize(fun, params, args=(W,n,m,N,M), callback=None)\n",
    "\n",
    "vals = res['x']\n",
    "\n",
    "A = vals[:N*M].reshape((N,M))\n",
    "X = vals[N*M:].reshape((M,n,m))\n",
    "\n",
    "#print (\"weights are:\")\n",
    "#print (A)\n",
    "\n",
    "#print (\"basis filters are:\")\n",
    "#print (W)\n",
    "\n",
    "#random check\n",
    "for i in range(N):\n",
    "    coeff_i = A[i,:]\n",
    "    A_sum = 0\n",
    "    for j in range(M):\n",
    "        A_sum += coeff_i[j]*X[j]\n",
    "    print (\"approximation of matrix\", i)\n",
    "    print (np.round((np.linalg.norm(W[i] - A_sum, 2))*100, 5), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = params[1].reshape((M,n,m))\n",
    "A = params[0].reshape((N,M))\n",
    "\n",
    "print(A[0,:])\n",
    "print(X[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "early termination X 21\n",
      "13.1404564886 %\n",
      "approximation of matrix 0\n",
      "99.81 %\n",
      "approximation of matrix 1\n",
      "47.01 %\n",
      "approximation of matrix 2\n",
      "32.29 %\n",
      "approximation of matrix 3\n",
      "140.47 %\n",
      "approximation of matrix 4\n",
      "49.03 %\n",
      "approximation of matrix 5\n",
      "155.2 %\n",
      "approximation of matrix 6\n",
      "79.79 %\n",
      "approximation of matrix 7\n",
      "71.03 %\n",
      "approximation of matrix 8\n",
      "124.86 %\n",
      "approximation of matrix 9\n",
      "81.31 %\n",
      "approximation of matrix 10\n",
      "124.17 %\n",
      "approximation of matrix 11\n",
      "97.91 %\n",
      "approximation of matrix 12\n",
      "87.15 %\n",
      "approximation of matrix 13\n",
      "110.57 %\n",
      "approximation of matrix 14\n",
      "127.96 %\n",
      "approximation of matrix 15\n",
      "82.89 %\n",
      "approximation of matrix 16\n",
      "113.36 %\n",
      "approximation of matrix 17\n",
      "65.5 %\n",
      "approximation of matrix 18\n",
      "97.99 %\n",
      "approximation of matrix 19\n",
      "27.97 %\n",
      "approximation of matrix 20\n",
      "93.19 %\n",
      "approximation of matrix 21\n",
      "54.7 %\n",
      "approximation of matrix 22\n",
      "81.57 %\n",
      "approximation of matrix 23\n",
      "106.38 %\n",
      "approximation of matrix 24\n",
      "33.0 %\n",
      "approximation of matrix 25\n",
      "80.99 %\n",
      "approximation of matrix 26\n",
      "117.81 %\n",
      "approximation of matrix 27\n",
      "47.04 %\n",
      "approximation of matrix 28\n",
      "93.99 %\n",
      "approximation of matrix 29\n",
      "114.69 %\n",
      "approximation of matrix 30\n",
      "112.67 %\n",
      "approximation of matrix 31\n",
      "96.88 %\n",
      "approximation of matrix 32\n",
      "104.32 %\n",
      "approximation of matrix 33\n",
      "148.26 %\n",
      "approximation of matrix 34\n",
      "71.87 %\n",
      "approximation of matrix 35\n",
      "41.91 %\n",
      "approximation of matrix 36\n",
      "142.4 %\n",
      "approximation of matrix 37\n",
      "168.52 %\n",
      "approximation of matrix 38\n",
      "22.06 %\n",
      "approximation of matrix 39\n",
      "166.26 %\n",
      "approximation of matrix 40\n",
      "51.73 %\n",
      "approximation of matrix 41\n",
      "146.64 %\n",
      "approximation of matrix 42\n",
      "103.27 %\n",
      "approximation of matrix 43\n",
      "38.23 %\n",
      "approximation of matrix 44\n",
      "92.78 %\n",
      "approximation of matrix 45\n",
      "147.19 %\n",
      "approximation of matrix 46\n",
      "51.04 %\n",
      "approximation of matrix 47\n",
      "103.39 %\n",
      "approximation of matrix 48\n",
      "74.37 %\n",
      "approximation of matrix 49\n",
      "51.85 %\n",
      "approximation of matrix 50\n",
      "69.17 %\n",
      "approximation of matrix 51\n",
      "109.52 %\n",
      "approximation of matrix 52\n",
      "98.61 %\n",
      "approximation of matrix 53\n",
      "109.24 %\n",
      "approximation of matrix 54\n",
      "126.24 %\n",
      "approximation of matrix 55\n",
      "106.02 %\n",
      "approximation of matrix 56\n",
      "94.37 %\n",
      "approximation of matrix 57\n",
      "119.75 %\n",
      "approximation of matrix 58\n",
      "52.86 %\n",
      "approximation of matrix 59\n",
      "98.81 %\n",
      "approximation of matrix 60\n",
      "82.53 %\n",
      "approximation of matrix 61\n",
      "102.99 %\n",
      "approximation of matrix 62\n",
      "95.53 %\n",
      "approximation of matrix 63\n",
      "107.36 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cvx\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "# objective function to minimize:\n",
    "# Sum (W - Sum a*s)\n",
    "\n",
    "N = 64 #number of filters\n",
    "M = 15\n",
    "\n",
    "#filter sizes:\n",
    "n = 5\n",
    "m = 5\n",
    "\n",
    "#generate random sequence of filters\n",
    "\n",
    "W = np.random.rand(N, n*m) \n",
    "\n",
    "# starting point\n",
    "A = np.random.rand(N, M)\n",
    "X = np.random.rand(M, n*m)\n",
    "\n",
    "Max_Iter = 300\n",
    "A_var = cvx.Variable(N, M)\n",
    "X_var = cvx.Variable(M, n*m)\n",
    "\n",
    "\n",
    "for i in range(Max_Iter):\n",
    "    \n",
    "    if i%5 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    objective_A = cvx.Minimize(cvx.norm(W - A_var*X,1))\n",
    "    problem_A = cvx.Problem(objective_A, [])\n",
    "    result_A = problem_A.solve() #solver = \"SCS\"\n",
    "    \n",
    "    if (np.linalg.norm(A - A_var.value,2) < 1e-7):\n",
    "        print (\"early termination A\",i)\n",
    "        break\n",
    "    \n",
    "    A = A_var.value\n",
    "    \n",
    "    objective_X = cvx.Minimize(cvx.norm(W - A*X_var,1))\n",
    "    problem_X = cvx.Problem(objective_X, [])\n",
    "    result_X  = problem_X.solve()\n",
    "    \n",
    "    if (np.linalg.norm(X - X_var.value,2) < 1e-7):\n",
    "        print (\"early termination X\",i)\n",
    "        break\n",
    "    \n",
    "    X = X_var.value\n",
    "    \n",
    "    \n",
    "print((np.linalg.norm(W - np.matmul(A,X),2)/(np.linalg.norm(W,2)))*100,\"%\")\n",
    "\n",
    "#recovering the original structure\n",
    "W = np.reshape(W,(N,n,m))\n",
    "\n",
    "A = A.view(type = np.ndarray)\n",
    "X = X.view(type = np.ndarray)\n",
    "\n",
    "A = np.reshape(A,(N,M))\n",
    "X = np.reshape(X,(M,n,m))\n",
    "\n",
    "#check\n",
    "for i in range(N):\n",
    "    A_sum = 0\n",
    "    for j in range(M):\n",
    "        A_sum += A[i,j]*X[j,:,:]\n",
    "    print (\"approximation of matrix\", i)\n",
    "    print (np.round((np.linalg.norm(W[i,:,:] - A_sum,1))*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.317  0.601  0.502  0.223  0.516]\n",
      " [ 0.412  0.139  0.001  0.24   0.584]\n",
      " [ 0.23   0.294  0.48   0.841  0.063]\n",
      " [ 0.072  0.267  0.673  0.692  0.074]\n",
      " [ 0.233  0.856  0.545  0.942  0.583]]\n"
     ]
    }
   ],
   "source": [
    "print (np.matrix.round(X[2,:,:],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorized implementation of basis decomposition with nuclear norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 32)\n",
      "c =  0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "early termination A 54\n",
      "done\n",
      "approximation of matrix 0\n",
      "38.34 %\n",
      "and some random?\n",
      "286.41 %\n",
      "approximation of matrix 1\n",
      "15.63 %\n",
      "and some random?\n",
      "308.31 %\n",
      "approximation of matrix 2\n",
      "8.45 %\n",
      "and some random?\n",
      "272.74 %\n",
      "approximation of matrix 3\n",
      "12.15 %\n",
      "and some random?\n",
      "275.56 %\n",
      "approximation of matrix 4\n",
      "18.92 %\n",
      "and some random?\n",
      "292.13 %\n",
      "approximation of matrix 5\n",
      "10.6 %\n",
      "and some random?\n",
      "318.19 %\n",
      "approximation of matrix 6\n",
      "19.41 %\n",
      "and some random?\n",
      "286.08 %\n",
      "approximation of matrix 7\n",
      "18.96 %\n",
      "and some random?\n",
      "293.1 %\n",
      "approximation of matrix 8\n",
      "29.79 %\n",
      "and some random?\n",
      "274.53 %\n",
      "approximation of matrix 9\n",
      "22.59 %\n",
      "and some random?\n",
      "337.55 %\n",
      "approximation of matrix 10\n",
      "10.6 %\n",
      "and some random?\n",
      "304.45 %\n",
      "approximation of matrix 11\n",
      "17.35 %\n",
      "and some random?\n",
      "240.9 %\n",
      "approximation of matrix 12\n",
      "19.75 %\n",
      "and some random?\n",
      "288.69 %\n",
      "approximation of matrix 13\n",
      "16.92 %\n",
      "and some random?\n",
      "272.33 %\n",
      "approximation of matrix 14\n",
      "22.14 %\n",
      "and some random?\n",
      "303.5 %\n",
      "approximation of matrix 15\n",
      "6.79 %\n",
      "and some random?\n",
      "289.28 %\n",
      "approximation of matrix 16\n",
      "16.89 %\n",
      "and some random?\n",
      "225.22 %\n",
      "approximation of matrix 17\n",
      "23.23 %\n",
      "and some random?\n",
      "288.3 %\n",
      "approximation of matrix 18\n",
      "11.31 %\n",
      "and some random?\n",
      "346.23 %\n",
      "approximation of matrix 19\n",
      "19.68 %\n",
      "and some random?\n",
      "300.2 %\n",
      "approximation of matrix 20\n",
      "8.15 %\n",
      "and some random?\n",
      "321.31 %\n",
      "approximation of matrix 21\n",
      "11.6 %\n",
      "and some random?\n",
      "288.23 %\n",
      "approximation of matrix 22\n",
      "7.51 %\n",
      "and some random?\n",
      "278.77 %\n",
      "approximation of matrix 23\n",
      "5.84 %\n",
      "and some random?\n",
      "337.32 %\n",
      "approximation of matrix 24\n",
      "12.82 %\n",
      "and some random?\n",
      "256.44 %\n",
      "approximation of matrix 25\n",
      "11.37 %\n",
      "and some random?\n",
      "303.72 %\n",
      "approximation of matrix 26\n",
      "11.57 %\n",
      "and some random?\n",
      "271.47 %\n",
      "approximation of matrix 27\n",
      "18.85 %\n",
      "and some random?\n",
      "325.32 %\n",
      "approximation of matrix 28\n",
      "20.01 %\n",
      "and some random?\n",
      "297.8 %\n",
      "approximation of matrix 29\n",
      "10.36 %\n",
      "and some random?\n",
      "308.72 %\n",
      "approximation of matrix 30\n",
      "10.97 %\n",
      "and some random?\n",
      "274.99 %\n",
      "approximation of matrix 31\n",
      "16.23 %\n",
      "and some random?\n",
      "287.45 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cvx\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# returns low-basis representation of original weights W with shape N x n x m by\n",
    "# linear combination of N matrices n x m with coefficients stored in matrix A\n",
    "def find_basis(W, M, lmbd, Max_Iter, norm,tol):\n",
    "    \n",
    "    N = W.shape[0]\n",
    "    n = W.shape[1]\n",
    "    m = W.shape[2]\n",
    "    \n",
    "    # starting point\n",
    "    W = W.reshape(N,n*m)\n",
    "    \n",
    "    A = np.random.rand(N, M)\n",
    "    X = np.random.rand(M, n*m)\n",
    "\n",
    "    A_var = cvx.Variable(N, M)\n",
    "    X_var = cvx.Variable(M, n*m)\n",
    "\n",
    "\n",
    "    for i in range(Max_Iter):\n",
    "\n",
    "        if i%1 == 0:\n",
    "            print(i)\n",
    "\n",
    "        objective_A = cvx.Minimize(cvx.norm(W - A_var*X,norm))\n",
    "        problem_A = cvx.Problem(objective_A, [])\n",
    "        result_A = problem_A.solve() \n",
    "\n",
    "        if (np.linalg.norm(A - A_var.value,norm) < tol):\n",
    "            print (\"early termination A\",i)\n",
    "            break\n",
    "\n",
    "        A = A_var.value\n",
    "\n",
    "        #adding nuclear norm\n",
    "        sum_nucl = 0\n",
    "        slvr = None\n",
    "        if lmbd != 0:\n",
    "            slvr = \"SCS\"\n",
    "            for j in range(M):\n",
    "                x = X_var[j,:]\n",
    "                x = cvx.reshape(x,n,m)\n",
    "                sum_nucl += cvx.norm(x, 'nuc')\n",
    "\n",
    "        objective_X = cvx.Minimize(cvx.norm(W - A*X_var,norm) + lmbd*sum_nucl)\n",
    "        problem_X = cvx.Problem(objective_X, [])\n",
    "        result_X  = problem_X.solve(solver = slvr)\n",
    "\n",
    "        if (np.linalg.norm(X - X_var.value,norm) < tol):\n",
    "            print (\"early termination X\",i)\n",
    "            break\n",
    "\n",
    "        X = X_var.value\n",
    "\n",
    "\n",
    "    #print((np.linalg.norm(W - np.matmul(A,X),2)/(np.linalg.norm(W,2)))*100,\"%\")\n",
    "\n",
    "    #recovering the original structure\n",
    "    A = A.view(type = np.ndarray)\n",
    "    X = X.view(type = np.ndarray)\n",
    "\n",
    "    A = np.reshape(A,(N,M))\n",
    "    X = np.reshape(X,(M,n,m))\n",
    "    \n",
    "    return A, X\n",
    "\n",
    "\n",
    "# N = 64 #number of filters\n",
    "\n",
    "\n",
    "# #filter size:\n",
    "# n = 5\n",
    "# m = 5\n",
    "\n",
    "# #generate random sequence of filters\n",
    "\n",
    "# W = np.random.rand(N,n,m) \n",
    "M = 14\n",
    "#loading data\n",
    "data = np.load('/home/pavel/Documents/Skoltech/NLA_Project/variables/scheme1_fr.npz')\n",
    "shp = data['conv1/weights'].shape\n",
    "new_weights = np.zeros((shp[0],shp[1],shp[2],M))\n",
    "coeffs = np.zeros(shp[2],shp[3],M)\n",
    "data = data['conv1/weights']\n",
    "data = np.swapaxes(data, 0,3 )\n",
    "data = np.swapaxes(data, 1,2 )\n",
    "data = np.swapaxes(data, 1,3 )\n",
    "\n",
    "#now channels axis is the last one\n",
    "for c in range(data.shape[3]):\n",
    "    print (\"c = \",c)\n",
    "    W = data[:,:,:,c]\n",
    "    A, X = find_basis(W, M, lmbd = 0, Max_Iter = 100, norm = 1, tol = 1e-7)\n",
    "    print (\"done\")\n",
    "    #check\n",
    "    for i in range(data.shape[0]):\n",
    "        A_sum = 0\n",
    "        for j in range(M):\n",
    "            A_sum += A[i,j]*X[j,:,:]\n",
    "        print (\"approximation of matrix\", i)\n",
    "        print (np.round((np.linalg.norm(W[i,:,:] - A_sum,1))*100, 2), \"%\")\n",
    "        print (\"and some random?\")\n",
    "        print (np.round((np.linalg.norm(W[i,:,:] - np.random.rand(n,m)))*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32768\n",
      "[ 3.307  0.905  0.738  0.518  0.139]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "U,Sigma, V = np.linalg.svd(X[5,:,:])\n",
    "print(np.matrix.round(Sigma,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# decomposition using 1-rank matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "early termination X 3\n",
      "approximation of matrix 0 , 101.2 %\n",
      "and comparison with random matrix? 0 , 232.6 %\n",
      "SVD decomposition? 110.5 %\n",
      "approximation of matrix 1 , 82.0 %\n",
      "and comparison with random matrix? 1 , 194.6 %\n",
      "SVD decomposition? 106.9 %\n",
      "approximation of matrix 2 , 97.5 %\n",
      "and comparison with random matrix? 2 , 234.7 %\n",
      "SVD decomposition? 109.2 %\n",
      "approximation of matrix 3 , 125.3 %\n",
      "and comparison with random matrix? 3 , 214.0 %\n",
      "SVD decomposition? 119.2 %\n",
      "approximation of matrix 4 , 55.1 %\n",
      "and comparison with random matrix? 4 , 199.1 %\n",
      "SVD decomposition? 81.4 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cvx\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def find_1_rank_decomposition(W, N,K, n, m, Max_Iter, norm,tol):\n",
    "    # starting point\n",
    "    W = W.reshape(N,n*m)\n",
    "    # initializing variable to optimize\n",
    "    v_var = []\n",
    "    h_var = []\n",
    "    v = []\n",
    "    h = []\n",
    "    for k in range(K):\n",
    "        v_var.append(cvx.Variable(n,N))\n",
    "        h_var.append(cvx.Variable(N,m))\n",
    "\n",
    "        # starting point \n",
    "        v.append(np.random.rand(n,N))\n",
    "        h.append(np.random.rand(N,m))\n",
    "    \n",
    "    for i in range(Max_Iter):\n",
    "\n",
    "        if i%10 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        fun_v = 0\n",
    "        for j in range(N):\n",
    "            for k in range(K):\n",
    "            \n",
    "                #temp1 = v_var[:,j]*np.array([h[j,:]])\n",
    "                if np.array([h[k][j,:]]).shape == (1,m):\n",
    "                    if k == 0:\n",
    "                        temp1 = v_var[k][:,j]*np.array([h[k][j,:]])\n",
    "                    else: \n",
    "                        temp1 += v_var[k][:,j]*np.array([h[k][j,:]])\n",
    "                else:\n",
    "                    if k == 0:\n",
    "                        temp1 = v_var[k][:,j]*np.array(h[k][j,:])\n",
    "                    else:\n",
    "                        temp1 += v_var[k][:,j]*np.array(h[k][j,:])\n",
    "                        \n",
    "            temp1 = cvx.reshape(temp1,n*m,1)\n",
    "            fun_v += cvx.norm(W[j,:] - temp1,norm)\n",
    "        \n",
    "        \n",
    "        objective_v = cvx.Minimize(fun_v)\n",
    "        problem_v = cvx.Problem(objective_v, [])\n",
    "        result_v = problem_v.solve() #solver = \"SCS\"\n",
    "        \n",
    "        if (np.linalg.norm(v[0] - v_var[0].value,norm) < tol):\n",
    "            print (\"early termination v\",i)\n",
    "            break\n",
    "\n",
    "        for k in range(K): \n",
    "            v[k] = v_var[k].value\n",
    "            \n",
    "        fun_h = 0\n",
    "\n",
    "        for j in range(N):\n",
    "            for k in range(K):\n",
    "                if k == 0:\n",
    "                    temp2 = np.array(v[k][:,j])*h_var[k][j,:]\n",
    "                else:\n",
    "                    temp2 += np.array(v[k][:,j])*h_var[k][j,:]\n",
    "            temp2 = cvx.reshape(temp2,n*m,1)\n",
    "            fun_h += cvx.norm(W[j,:] - temp2,norm)\n",
    "               \n",
    "        objective_h = cvx.Minimize(fun_h)\n",
    "        problem_h = cvx.Problem(objective_h, [])\n",
    "        result_h  = problem_h.solve() #solver = \"SCS\"\n",
    "        if (np.linalg.norm(h[0] - h_var[0].value,norm) < tol):\n",
    "            print (\"early termination X\",i)\n",
    "            break\n",
    "\n",
    "        for k in range(K): \n",
    "            h[k] = h_var[k].value\n",
    "    #recovering the original structure\n",
    "    for k in range(K):\n",
    "        h[k] = h[k].view(type = np.ndarray)\n",
    "        v[k] = v[k].view(type = np.ndarray)\n",
    "    \n",
    "    return h, v\n",
    "\n",
    "\n",
    "N = 5 #number of filters\n",
    "\n",
    "#filter size:\n",
    "n = 5\n",
    "m = 5\n",
    "\n",
    "#generate random sequence of filters\n",
    "\n",
    "W = np.random.rand(N,n,m) \n",
    "K = 2\n",
    "\n",
    "H, V = find_1_rank_decomposition(W, N,K, n, m, Max_Iter = 300, norm = 1, tol = 1e-8)\n",
    "#check\n",
    "for i in range(N):\n",
    "\n",
    "    res = 0\n",
    "    for k in range(K):\n",
    "        res += np.matmul(np.array([H[k][i,:]]).T,np.array([V[k][:,i]]))\n",
    "        \n",
    "    print (\"approximation of matrix\", i, \",\",\n",
    "          np.round((np.linalg.norm(W[i,:,:] - res,1))*100, 1), \"%\")\n",
    "    print (\"and comparison with random matrix?\",i,\",\",\n",
    "            np.round((np.linalg.norm(W[i,:,:] - np.random.rand(n,m)))*100, 1), \"%\")\n",
    "    S,Z,D = np.linalg.svd(W[i,:,:])\n",
    "    l = 1\n",
    "    W_ = np.dot(S[:,:l], np.dot(np.diag(Z)[:l,:l], D[:l,:]))\n",
    "    print (\"SVD decomposition?\",np.round(np.linalg.norm(W[i,:,:] - W_)*100, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "approximation of matrix 0\n",
      "86.45 %\n",
      "approximation of matrix 1\n",
      "0.03 %\n",
      "approximation of matrix 2\n",
      "26.98 %\n",
      "approximation of matrix 3\n",
      "26.99 %\n",
      "approximation of matrix 4\n",
      "0.75 %\n",
      "approximation of matrix 5\n",
      "0.11 %\n",
      "approximation of matrix 6\n",
      "0.03 %\n",
      "approximation of matrix 7\n",
      "16.57 %\n",
      "approximation of matrix 8\n",
      "19.2 %\n",
      "approximation of matrix 9\n",
      "29.21 %\n",
      "approximation of matrix 10\n",
      "29.32 %\n",
      "approximation of matrix 11\n",
      "15.73 %\n",
      "approximation of matrix 12\n",
      "15.87 %\n",
      "approximation of matrix 13\n",
      "0.37 %\n",
      "approximation of matrix 14\n",
      "0.38 %\n",
      "[[ 0.5808218   0.99735639  0.50303305]\n",
      " [ 0.41543549  0.15780439  0.05742168]\n",
      " [ 0.80647582  0.42009534  0.53532226]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cvx\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "# objective function to minimize:\n",
    "# Sum (W - Sum a*s)\n",
    "\n",
    "N = 15 #number of filters\n",
    "M = 8\n",
    "\n",
    "#filter sizes:\n",
    "n = 3\n",
    "m = 3\n",
    "\n",
    "#generate random sequence of filters\n",
    "\n",
    "W = np.random.rand(N, n, m) \n",
    "\n",
    "# starting point\n",
    "A = np.random.rand(N,M)\n",
    "X = np.random.rand(M,n,m)\n",
    "\n",
    "S = []\n",
    "for i in range(M):\n",
    "    S.append(cvx.Variable(n,m))\n",
    "\n",
    "# S = cvx.Variable(M,n,m)\n",
    "A_var = cvx.Variable(N, M)\n",
    "\n",
    "Max_Iter = 5\n",
    "\n",
    "\n",
    "for i in range(Max_Iter):\n",
    "    \n",
    "    if i%5 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    fun_A = 0\n",
    "    f_A = cvx.Variable(n,m)\n",
    "    for p in range(N): \n",
    "        f_A += W[p,:,:]\n",
    "        for k in range(M):\n",
    "            f_A -= A_var[p,k]*X[k,:,:]\n",
    "        fun_A += cvx.norm(f_A,1)\n",
    "\n",
    "    objective_A = cvx.Minimize(fun_A)\n",
    "    problem_A = cvx.Problem(objective_A, [])\n",
    "    result_A = problem_A.solve(solver = \"SCS\") #solver = \"SCS\"\n",
    "    if (np.linalg.norm(A - A_var.value,2) < 1e-7):\n",
    "        print (\"early termination A\",i)\n",
    "        break\n",
    "    \n",
    "    A = A_var.value\n",
    "    \n",
    "    fun_X = 0\n",
    "    f_X = cvx.Variable(n,m)\n",
    "    for p in range(N):\n",
    "        f_X += W[p,:,:]  \n",
    "        for k in range(M):\n",
    "            f_X -= A[p,k]*S[k]\n",
    "        fun_X += cvx.norm(f_X,1)\n",
    "        #fun_X += 1.5*cvx.norm(S[k],'nuc')\n",
    "    \n",
    "    objective_X = cvx.Minimize(fun_X)\n",
    "    problem_X = cvx.Problem(objective_X, [])\n",
    "    result_X  = problem_X.solve(solver = \"SCS\")\n",
    "    \n",
    "    # here check for norm of X\n",
    "    diff = 0\n",
    "    for j in range(M):\n",
    "        diff += np.linalg.norm(X[j,:,:] - S[j].value,2)\n",
    "        \n",
    "    if (diff < 1e-7):\n",
    "        print (\"early termination X\",i)\n",
    "        break\n",
    "    \n",
    "    for j in range(M):\n",
    "        X[j,:,:] = S[j].value\n",
    "    \n",
    "\n",
    "\n",
    "#recovering the original structure\n",
    "\n",
    "A = A.view(type = np.ndarray)\n",
    "X = X.view(type = np.ndarray)\n",
    "\n",
    "#check\n",
    "for i in range(N):\n",
    "    A_sum = 0\n",
    "    for j in range(M):\n",
    "        A_sum += A[i,j]*X[j,:,:]\n",
    "    print (\"approximation of matrix\", i)\n",
    "    print (np.round((np.linalg.norm(W[i,:,:] - A_sum,1))*100, 2), \"%\")\n",
    "\n",
    "print(X[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.84100492  0.59970226  0.20291488]\n"
     ]
    }
   ],
   "source": [
    "U,Sigma, V = np.linalg.svd(X[3,:,:])\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cvx\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# returns low-basis representation of original weights W with shape N x n x m by\n",
    "# linear combination of N matrices n x m with coefficients stored in matrix A\n",
    "def find_basis(W, M, lmbd, Max_Iter, norm,tol):\n",
    "    \n",
    "    N = W.shape[0]\n",
    "    n = W.shape[1]\n",
    "    m = W.shape[2]\n",
    "    \n",
    "    # starting point\n",
    "    W = W.reshape(N,n*m)\n",
    "    \n",
    "    A = np.random.rand(N, M)\n",
    "    X = np.random.rand(M, n*m)\n",
    "\n",
    "    A_var = cvx.Variable(N, M)\n",
    "    X_var = cvx.Variable(M, n*m)\n",
    "\n",
    "\n",
    "    for i in range(Max_Iter):\n",
    "\n",
    "        if i%1 == 0:\n",
    "            print(i)\n",
    "\n",
    "        objective_A = cvx.Minimize(cvx.norm(W - A_var*X,norm))\n",
    "        problem_A = cvx.Problem(objective_A, [])\n",
    "        result_A = problem_A.solve() \n",
    "\n",
    "        if (np.linalg.norm(A - A_var.value,norm) < tol):\n",
    "            print (\"early termination A\",i)\n",
    "            break\n",
    "\n",
    "        A = A_var.value\n",
    "\n",
    "        #adding nuclear norm\n",
    "        sum_nucl = 0\n",
    "        slvr = None\n",
    "        if lmbd != 0:\n",
    "            slvr = \"SCS\"\n",
    "            for j in range(M):\n",
    "                x = X_var[j,:]\n",
    "                x = cvx.reshape(x,n,m)\n",
    "                sum_nucl += cvx.norm(x, 'nuc')\n",
    "\n",
    "        objective_X = cvx.Minimize(cvx.norm(W - A*X_var,norm) + lmbd*sum_nucl)\n",
    "        problem_X = cvx.Problem(objective_X, [])\n",
    "        result_X  = problem_X.solve(solver = slvr)\n",
    "\n",
    "        if (np.linalg.norm(X - X_var.value,norm) < tol):\n",
    "            print (\"early termination X\",i)\n",
    "            break\n",
    "\n",
    "        X = X_var.value\n",
    "\n",
    "\n",
    "    #print((np.linalg.norm(W - np.matmul(A,X),2)/(np.linalg.norm(W,2)))*100,\"%\")\n",
    "\n",
    "    #recovering the original structure\n",
    "    A = A.view(type = np.ndarray)\n",
    "    X = X.view(type = np.ndarray)\n",
    "\n",
    "    A = np.reshape(A,(N,M))\n",
    "    X = np.reshape(X,(M,n,m))\n",
    "    \n",
    "    return A, X\n",
    "\n",
    "\n",
    "# N = 64 #number of filters\n",
    "\n",
    "\n",
    "# #filter size:\n",
    "# n = 5\n",
    "# m = 5\n",
    "\n",
    "# #generate random sequence of filters\n",
    "\n",
    "# W = np.random.rand(N,n,m) \n",
    "M = 14\n",
    "#loading data\n",
    "data = np.load('variables/scheme1_fr.npz')\n",
    "shp = data['conv2/weights'].shape\n",
    "# new_weights = np.zeros((shp[0],shp[1],shp[2],M))\n",
    "# coeffs = np.zeros(shp[2],shp[3],M)\n",
    "data = data['conv2/weights']\n",
    "C = data.shape[2]\n",
    "N = data.shape[3]\n",
    "data = data.reshape(shp[0],shp[1],-1)\n",
    "data = np.swapaxes(data, 0,2 )\n",
    "data = np.swapaxes(data, 1,2 )\n",
    "W = data\n",
    "#now channels axis is the last one\n",
    "\n",
    "A, X = find_basis(W, M, lmbd = 0, Max_Iter = 100, norm = 1, tol = 1e-7)\n",
    "\n",
    "\n",
    "#check\n",
    "print (data.shape[0])\n",
    "for i in range(N):\n",
    "    A_sum = 0\n",
    "    for j in range(M):\n",
    "        A_sum += A[i,j]*X[j,:,:]\n",
    "    print (\"approximation of matrix\", i)\n",
    "    print (np.round((np.linalg.norm(W[i,:,:] - A_sum,1))*100, 1), \"%\")\n",
    "    \n",
    "A = A.reshape(C,N,M)\n",
    "# A - matrix of coefficients N*C by M, X\n",
    "np.savez('variables/scheme1_fr_decomposition.npz', coeffs = A, basis = X )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]]\n",
      "\n",
      " [[ 9 10 11]\n",
      "  [12 13 14]\n",
      "  [15 16 17]]\n",
      "\n",
      " [[18 19 20]\n",
      "  [21 22 23]\n",
      "  [24 25 26]]]\n",
      "[[ 0  1  2  3  4  5  6  7  8]\n",
      " [ 9 10 11 12 13 14 15 16 17]\n",
      " [18 19 20 21 22 23 24 25 26]]\n"
     ]
    }
   ],
   "source": [
    "G = np.array([range(27)]).reshape(3,3,3)\n",
    "print(G)\n",
    "\n",
    "print(G.reshape(3,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
